{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b98312df-3255-4de6-abd9-bef77906c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATASET = './Dataset/batch2'\n",
    "DATASET_SOURCE = os.path.join(DATASET, 'source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09f23377-2ee2-40cd-aa65-8af955734661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "SOURCE = \"./Dataset/Raw/batch1.zip\"\n",
    "\n",
    "if os.path.exists(SOURCE):\n",
    "    with zipfile.ZipFile(SOURCE, 'r') as zip_ref:\n",
    "        zip_ref.extractall(DATASET_SOURCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7aedc35a-4a7c-485a-aa59-4a84921c395c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n",
      "390\n",
      "['img000002.jpg', 'img000003.jpg', 'img000004.jpg', 'img000005.jpg', 'img000006.jpg']\n",
      "['img000002.txt', 'img000003.txt', 'img000004.txt', 'img000005.txt', 'img000006.txt']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATASET_IMG = os.path.join(DATASET_SOURCE, 'images/train')\n",
    "DATASET_LBL = os.path.join(DATASET_SOURCE, 'labels/train')\n",
    "\n",
    "images = os.listdir(DATASET_IMG)\n",
    "labels = os.listdir(DATASET_LBL)\n",
    "\n",
    "print(len(images))\n",
    "print(len(labels))\n",
    "\n",
    "print(images[:5])\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "885c1d22-b12b-4158-bd9d-85742efd0e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n"
     ]
    }
   ],
   "source": [
    "# ensure that all images have labels\n",
    "files = []\n",
    "for image in images:\n",
    "    filename = image.split('.')[0]\n",
    "    label = filename + '.txt'\n",
    "    if label in labels:\n",
    "        files.append(filename)\n",
    "\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0d3b6d6-522a-42c2-ae10-6681c364dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train (70%), val (20%), test (10%)\n",
    "# train, test = train_test_split(files, test_size=0.1, random_state=42)\n",
    "train, val = train_test_split(files, test_size=0.3, random_state=42)  # 0.22 * 0.9 â‰ˆ 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "824a20d3-a882-4d90-859b-c2b943a68e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img000002', 'img000003', 'img000004', 'img000005', 'img000006']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d99b4bb4-442d-48c3-a3e2-72fd7b9e2594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273:117\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train)}:{len(val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "479089c6-9503-4e8a-8c76-8669b5f1a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATASET, \"train\")\n",
    "VAL_PATH = os.path.join(DATASET, \"val\")\n",
    "TEST_PATH = os.path.join(DATASET, \"test\")\n",
    "\n",
    "os.makedirs(os.path.join(TRAIN_PATH, \"images\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(TRAIN_PATH, \"labels\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(VAL_PATH, \"images\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(VAL_PATH, \"labels\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(TEST_PATH, \"images\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(TEST_PATH, \"labels\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0518c0eb-55de-48fd-83dc-636c4e416179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Dataset/batch2\\train\n",
      "./Dataset/batch2\\val\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m move_files(train, TRAIN_PATH)\n\u001b[32m     12\u001b[39m move_files(val, VAL_PATH)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m move_files(test, TEST_PATH)\n",
      "\u001b[31mNameError\u001b[39m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "# Move files\n",
    "def move_files(files, split):\n",
    "    print(split)\n",
    "    for f in files:\n",
    "        img = f + '.jpg'\n",
    "        lbl = f + '.txt'\n",
    "        # print(f\"file: {f}\")\n",
    "        os.rename(f\"{DATASET_IMG}/{img}\", f\"{split}/images/{img}\")\n",
    "        os.rename(f\"{DATASET_LBL}/{lbl}\", f\"{split}/labels/{lbl}\")\n",
    "\n",
    "move_files(train, TRAIN_PATH)\n",
    "move_files(val, VAL_PATH)\n",
    "# move_files(test, TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcf4597c-6834-4f3d-aa9a-6c1bc12ea5e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m df_train.head()\n\u001b[32m      4\u001b[39m df_train.to_csv(os.path.join(DATASET, \u001b[33m\"\u001b[39m\u001b[33mtrain.csv\u001b[39m\u001b[33m\"\u001b[39m), index=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df_test = pd.DataFrame({\u001b[33m\"\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m\"\u001b[39m: test})\n\u001b[32m      7\u001b[39m df_test.head()\n\u001b[32m      8\u001b[39m df_test.to_csv(os.path.join(DATASET, \u001b[33m\"\u001b[39m\u001b[33mtest.csv\u001b[39m\u001b[33m\"\u001b[39m), index=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.DataFrame({\"filename\": train})\n",
    "df_train.head()\n",
    "df_train.to_csv(os.path.join(DATASET, \"train.csv\"), index=None)\n",
    "\n",
    "# df_test = pd.DataFrame({\"filename\": test})\n",
    "# df_test.head()\n",
    "# df_test.to_csv(os.path.join(DATASET, \"test.csv\"), index=None)\n",
    "\n",
    "df_val = pd.DataFrame({\"filename\": val})\n",
    "df_val.head()\n",
    "df_val.to_csv(os.path.join(DATASET, \"val.csv\"), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f71fb4-da00-4250-a668-0d322be83a5a",
   "metadata": {},
   "source": [
    "### End of Scripe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
